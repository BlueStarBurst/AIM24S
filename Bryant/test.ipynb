{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\texas\\anaconda3\\envs\\MovieDiff\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\users\\texas\\desktop\\personal\\aim24s\\bryant\\mobilesam\\mobile_sam\\modeling\\tiny_vit_sam.py:656: UserWarning: Overwriting tiny_vit_5m_224 in registry with mobile_sam.modeling.tiny_vit_sam.tiny_vit_5m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  return register_model(fn_wrapper)\n",
      "c:\\users\\texas\\desktop\\personal\\aim24s\\bryant\\mobilesam\\mobile_sam\\modeling\\tiny_vit_sam.py:656: UserWarning: Overwriting tiny_vit_11m_224 in registry with mobile_sam.modeling.tiny_vit_sam.tiny_vit_11m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  return register_model(fn_wrapper)\n",
      "c:\\users\\texas\\desktop\\personal\\aim24s\\bryant\\mobilesam\\mobile_sam\\modeling\\tiny_vit_sam.py:656: UserWarning: Overwriting tiny_vit_21m_224 in registry with mobile_sam.modeling.tiny_vit_sam.tiny_vit_21m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  return register_model(fn_wrapper)\n",
      "c:\\users\\texas\\desktop\\personal\\aim24s\\bryant\\mobilesam\\mobile_sam\\modeling\\tiny_vit_sam.py:656: UserWarning: Overwriting tiny_vit_21m_384 in registry with mobile_sam.modeling.tiny_vit_sam.tiny_vit_21m_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  return register_model(fn_wrapper)\n",
      "c:\\users\\texas\\desktop\\personal\\aim24s\\bryant\\mobilesam\\mobile_sam\\modeling\\tiny_vit_sam.py:656: UserWarning: Overwriting tiny_vit_21m_512 in registry with mobile_sam.modeling.tiny_vit_sam.tiny_vit_21m_512. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  return register_model(fn_wrapper)\n"
     ]
    }
   ],
   "source": [
    "from mobile_sam import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
    "import torch\n",
    "import cv2\n",
    "import os\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sam(\n",
       "  (image_encoder): TinyViT(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (seq): Sequential(\n",
       "        (0): Conv2d_BN(\n",
       "          (c): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Conv2d_BN(\n",
       "          (c): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layers): ModuleList(\n",
       "      (0): ConvLayer(\n",
       "        (blocks): ModuleList(\n",
       "          (0-1): 2 x MBConv(\n",
       "            (conv1): Conv2d_BN(\n",
       "              (c): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (act1): GELU(approximate='none')\n",
       "            (conv2): Conv2d_BN(\n",
       "              (c): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (act2): GELU(approximate='none')\n",
       "            (conv3): Conv2d_BN(\n",
       "              (c): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (act3): GELU(approximate='none')\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "        )\n",
       "        (downsample): PatchMerging(\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv1): Conv2d_BN(\n",
       "            (c): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv2): Conv2d_BN(\n",
       "            (c): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv3): Conv2d_BN(\n",
       "            (c): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): BasicLayer(\n",
       "        dim=128, input_resolution=(128, 128), depth=2\n",
       "        (blocks): ModuleList(\n",
       "          (0-1): 2 x TinyViTBlock(\n",
       "            dim=128, input_resolution=(128, 128), num_heads=4, window_size=7, mlp_ratio=4.0\n",
       "            (drop_path): Identity()\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
       "              (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "            )\n",
       "            (mlp): Mlp(\n",
       "              (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (local_conv): Conv2d_BN(\n",
       "              (c): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (downsample): PatchMerging(\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv1): Conv2d_BN(\n",
       "            (c): Conv2d(128, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv2): Conv2d_BN(\n",
       "            (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=160, bias=False)\n",
       "            (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv3): Conv2d_BN(\n",
       "            (c): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): BasicLayer(\n",
       "        dim=160, input_resolution=(64, 64), depth=6\n",
       "        (blocks): ModuleList(\n",
       "          (0-5): 6 x TinyViTBlock(\n",
       "            dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0\n",
       "            (drop_path): Identity()\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=160, out_features=480, bias=True)\n",
       "              (proj): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "            (mlp): Mlp(\n",
       "              (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
       "              (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (local_conv): Conv2d_BN(\n",
       "              (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (downsample): PatchMerging(\n",
       "          (act): GELU(approximate='none')\n",
       "          (conv1): Conv2d_BN(\n",
       "            (c): Conv2d(160, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv2): Conv2d_BN(\n",
       "            (c): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)\n",
       "            (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (conv3): Conv2d_BN(\n",
       "            (c): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): BasicLayer(\n",
       "        dim=320, input_resolution=(64, 64), depth=2\n",
       "        (blocks): ModuleList(\n",
       "          (0-1): 2 x TinyViTBlock(\n",
       "            dim=320, input_resolution=(64, 64), num_heads=10, window_size=7, mlp_ratio=4.0\n",
       "            (drop_path): Identity()\n",
       "            (attn): Attention(\n",
       "              (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (qkv): Linear(in_features=320, out_features=960, bias=True)\n",
       "              (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "            )\n",
       "            (mlp): Mlp(\n",
       "              (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "              (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (local_conv): Conv2d_BN(\n",
       "              (c): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm_head): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "    (head): Linear(in_features=320, out_features=1000, bias=True)\n",
       "    (neck): Sequential(\n",
       "      (0): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): LayerNorm2d()\n",
       "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (3): LayerNorm2d()\n",
       "    )\n",
       "  )\n",
       "  (prompt_encoder): PromptEncoder(\n",
       "    (pe_layer): PositionEmbeddingRandom()\n",
       "    (point_embeddings): ModuleList(\n",
       "      (0-3): 4 x Embedding(1, 256)\n",
       "    )\n",
       "    (not_a_point_embed): Embedding(1, 256)\n",
       "    (mask_downscaling): Sequential(\n",
       "      (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (1): LayerNorm2d()\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (4): LayerNorm2d()\n",
       "      (5): GELU(approximate='none')\n",
       "      (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (no_mask_embed): Embedding(1, 256)\n",
       "  )\n",
       "  (mask_decoder): MaskDecoder(\n",
       "    (transformer): TwoWayTransformer(\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x TwoWayAttentionBlock(\n",
       "          (self_attn): Attention(\n",
       "            (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (cross_attn_token_to_image): Attention(\n",
       "            (q_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (k_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (v_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (out_proj): Linear(in_features=128, out_features=256, bias=True)\n",
       "          )\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (lin1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (lin2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (act): ReLU()\n",
       "          )\n",
       "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (cross_attn_image_to_token): Attention(\n",
       "            (q_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (k_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (v_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (out_proj): Linear(in_features=128, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_attn_token_to_image): Attention(\n",
       "        (q_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (k_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (v_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (out_proj): Linear(in_features=128, out_features=256, bias=True)\n",
       "      )\n",
       "      (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (iou_token): Embedding(1, 256)\n",
       "    (mask_tokens): Embedding(4, 256)\n",
       "    (output_upscaling): Sequential(\n",
       "      (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (1): LayerNorm2d()\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (4): GELU(approximate='none')\n",
       "    )\n",
       "    (output_hypernetworks_mlps): ModuleList(\n",
       "      (0-3): 4 x MLP(\n",
       "        (layers): ModuleList(\n",
       "          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
       "          (2): Linear(in_features=256, out_features=32, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (iou_prediction_head): MLP(\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
       "        (2): Linear(in_features=256, out_features=4, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_type = \"vit_t\"\n",
    "sam_checkpoint = \"./MobileSAM/weights/mobile_sam.pt\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "mobile_sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "mobile_sam.to(device=device)\n",
    "mobile_sam.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\texas\\Desktop\\Personal\\AIM24S\\Bryant\\test_imgs\\labrador.jpg\n"
     ]
    }
   ],
   "source": [
    "\n",
    "abspath = os.path.abspath(\"\")\n",
    "print(os.path.join(os.path.dirname(abspath), \"Bryant\\\\test_imgs\\\\labrador.jpg\"))\n",
    "image = cv2.imread(os.path.join(os.path.dirname(abspath), \"Bryant\\\\test_imgs\\\\labrador.jpg\"))\n",
    "# turn into ndarray\n",
    "\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "predictor = SamPredictor(mobile_sam)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 89\u001b[0m\n\u001b[0;32m     86\u001b[0m t\u001b[38;5;241m.\u001b[39mstart()\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 89\u001b[0m     ret, frame \u001b[38;5;241m=\u001b[39m \u001b[43mcap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m     current_frame \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ret:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "\n",
    "# get stream of images using cv2\n",
    "cap = cv2.VideoCapture(0)\n",
    "ret, frame = cap.read()\n",
    "current_frame = frame\n",
    "masks = []\n",
    "\n",
    "def showStream():\n",
    "    global masks\n",
    "    global current_frame\n",
    "    # ind = int(ind)\n",
    "    # yeild the current frame forever\n",
    "    while True:\n",
    "        \n",
    "        \n",
    "        # turn bool to int\n",
    "        # print(len(masks))\n",
    "        \n",
    "        if len(masks) == 0:\n",
    "            print(\"No masks found\")\n",
    "            yield current_frame, current_frame\n",
    "            sleep(0.1)\n",
    "            continue\n",
    "        \n",
    "        # if ind >= len(masks):\n",
    "        #     ind = len(masks) - 1\n",
    "        \n",
    "        \n",
    "        \n",
    "        # turn (3, 480, 640) (480, 640, 3)\n",
    "        # masks = np.moveaxis(masks, 0, -1)\n",
    "        # print(masks.shape, current_frame.shape)\n",
    "        # print(current_frame)\n",
    "        # print(masks)\n",
    "        \n",
    "        yield current_frame, masks\n",
    "        sleep(0.01)\n",
    "    return None\n",
    "\n",
    "# create a gradio interface and output two images\n",
    "# iface = gr.Interface(\n",
    "#     fn=showStream,\n",
    "#     inputs=None,\n",
    "#     outputs=[\"image\", \"image\"],\n",
    "# ).queue(concurrency_count=5)\n",
    "# iface.launch()\n",
    "\n",
    "# create a gradio interface and output two images using blocks\n",
    "with gr.Blocks() as demo:\n",
    "    \n",
    "    with gr.Row():\n",
    "        out1 = gr.Image(label=\"Original Image\")\n",
    "        out2 = gr.Image(label=\"Masked Image\")\n",
    "    # slider = gr.Slider(minimum=0, maximum=10, default=0, label=\"Slider\", step=1)\n",
    "    btn = gr.Button(\"Run\")\n",
    "    btn.click(fn=showStream, inputs=None, outputs=[out1, out2])\n",
    "\n",
    "demo.queue()\n",
    "demo.launch()\n",
    "\n",
    "stop_threads = True\n",
    "sleep(1)\n",
    "stop_threads = False\n",
    "\n",
    "def updateMasks():\n",
    "    global masks\n",
    "    global current_frame\n",
    "    while True:\n",
    "        global stop_threads\n",
    "        if stop_threads:\n",
    "            break\n",
    "        predictor.set_image(current_frame)\n",
    "        # predictor.set_image(image)\n",
    "        tmasks, _, _ = predictor.predict()\n",
    "        tmasks = tmasks[0].astype(int)\n",
    "        # turn 0 and 1 to 0 and 255\n",
    "        tmasks = tmasks * 255\n",
    "        # turn into 3 channels\n",
    "        masks = np.stack([tmasks] * 3, axis=-1)\n",
    "\n",
    "# create a thread to update the masks\n",
    "import threading\n",
    "t = threading.Thread(target=updateMasks)\n",
    "t.start()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    current_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    if not ret:\n",
    "        print(\"Error: failed to capture image\")\n",
    "        break\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MainThread\n",
      "IOPub\n",
      "Heartbeat\n",
      "Control\n",
      "IPythonHistorySavingThread\n",
      "Thread-4\n",
      "Thread-8 (run)\n",
      "AnyIO worker thread\n",
      "Thread-13 (run)\n",
      "AnyIO worker thread\n"
     ]
    }
   ],
   "source": [
    "#get all threads\n",
    "import threading\n",
    "stop_threads = True\n",
    "for thread in threading.enumerate():\n",
    "    print(thread.name)\n",
    "    # if the thread contains the word \"updateMasks\"\n",
    "    if \"updateMasks\" in str(thread.name):\n",
    "        # join the thread\n",
    "        print(\"Joining thread\")\n",
    "        # thread.join()\n",
    "        # print(\"Thread joined\")\n",
    "        # break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.50.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# print gradio version\n",
    "print(gr.__version__)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MovieDiff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
